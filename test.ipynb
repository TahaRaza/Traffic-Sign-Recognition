{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Environment Setup",
   "id": "b4ea1e29245fb594"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T11:44:10.368240Z",
     "start_time": "2025-11-14T11:44:06.274202Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Model",
   "id": "6fa894d796864e8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:44:11.485051Z",
     "start_time": "2025-11-14T11:44:10.394606Z"
    }
   },
   "cell_type": "code",
   "source": "model = load_model(\"traffic_sign_model.keras\")",
   "id": "420f711cc9a68059",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Class Names",
   "id": "fd6bc68e8eb0504e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:44:15.083418Z",
     "start_time": "2025-11-14T11:44:15.076383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = {\n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)',\n",
    "    2:'Speed limit (50km/h)',\n",
    "    3:'Speed limit (60km/h)',\n",
    "    4:'Speed limit (70km/h)',\n",
    "    5:'Speed limit (80km/h)',\n",
    "    6:'End of speed limit (80km/h)',\n",
    "    7:'Speed limit (100km/h)',\n",
    "    8:'Speed limit (120km/h)',\n",
    "    9:'No passing',\n",
    "    10:'No passing veh over 3.5 tons',\n",
    "    11:'Right-of-way at intersection',\n",
    "    12:'Priority road',\n",
    "    13:'Yield',\n",
    "    14:'Stop',\n",
    "    15:'No vehicles',\n",
    "    16:'Veh > 3.5 tons prohibited',\n",
    "    17:'No entry',\n",
    "    18:'General caution',\n",
    "    19:'Dangerous curve left',\n",
    "    20:'Dangerous curve right',\n",
    "    21:'Double curve',\n",
    "    22:'Bumpy road',\n",
    "    23:'Slippery road',\n",
    "    24:'Road narrows on the right',\n",
    "    25:'Road work',\n",
    "    26:'Traffic signals',\n",
    "    27:'Pedestrians',\n",
    "    28:'Children crossing',\n",
    "    29:'Bicycles crossing',\n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing',\n",
    "    32:'End speed + passing limits',\n",
    "    33:'Turn right ahead',\n",
    "    34:'Turn left ahead',\n",
    "    35:'Ahead only',\n",
    "    36:'Go straight or right',\n",
    "    37:'Go straight or left',\n",
    "    38:'Keep right',\n",
    "    39:'Keep left',\n",
    "    40:'Roundabout mandatory',\n",
    "    41:'End of no passing',\n",
    "    42:'End no passing veh > 3.5 tons'\n",
    "}"
   ],
   "id": "ee5d42b6715b3147",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Scan Video",
   "id": "f213230081cf6386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:57:11.524151Z",
     "start_time": "2025-11-14T11:44:15.098115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_path = \"clip_segment.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps\n",
    "\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Frames:\", frame_count)\n",
    "print(\"Duration:\", duration, \"sec\")\n",
    "\n",
    "timestamps = []\n",
    "\n",
    "frame_number = 0\n",
    "SKIP = 5  # check every 5th frame\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_number % SKIP == 0:\n",
    "        img = cv2.resize(frame, (224, 224))\n",
    "        img = img.astype(\"float32\") / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        preds = model.predict(img, verbose=0)\n",
    "        class_id = np.argmax(preds)\n",
    "        confidence = preds[0][class_id]\n",
    "\n",
    "        if confidence > 0.8:\n",
    "            timestamps.append(frame_number / fps)\n",
    "\n",
    "    frame_number += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"✅ Finished scanning video\")\n",
    "print(\"Total detections found:\", len(timestamps))"
   ],
   "id": "4dd30971cc6e9ba3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0\n",
      "Frames: 35249\n",
      "Duration: 1174.9666666666667 sec\n",
      "✅ Finished scanning video\n",
      "Total detections found: 1822\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Filter Segment",
   "id": "109a50038dce01fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:57:11.651797Z",
     "start_time": "2025-11-14T11:57:11.643589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "segment_start = 50\n",
    "segment_end = 1625\n",
    "\n",
    "segment_detections = [t for t in timestamps if segment_start <= t <= segment_end]\n",
    "\n",
    "print(\"\\n✅ Detection Summary for Segment 14:10 → 33:45\")\n",
    "print(\"Detections inside segment:\", len(segment_detections))\n",
    "\n",
    "if segment_detections:\n",
    "    print(\"\\nFirst 10 timestamps:\")\n",
    "    print(segment_detections[:10])"
   ],
   "id": "d2cdee732b311077",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Detection Summary for Segment 14:10 → 33:45\n",
      "Detections inside segment: 1583\n",
      "\n",
      "First 10 timestamps:\n",
      "[50.0, 50.166666666666664, 50.333333333333336, 50.5, 50.666666666666664, 50.833333333333336, 51.0, 51.166666666666664, 51.333333333333336, 51.5]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:08:38.463395Z",
     "start_time": "2025-11-14T11:57:11.668339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "# --- Input clip ---\n",
    "input_video = \"clip_segment.mp4\"\n",
    "output_video = \"linkedin_demo.mp4\"\n",
    "\n",
    "# --- Load video ---\n",
    "cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# --- Output writer ---\n",
    "out = cv2.VideoWriter(\n",
    "    output_video,\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    fps,\n",
    "    (width, height)\n",
    ")\n",
    "\n",
    "# ✅ Your timestamps list (sorted)\n",
    "detections = sorted(timestamps)      # <-- make sure 'timestamps' exists\n",
    "\n",
    "i = 0  # detection counter index\n",
    "\n",
    "print(\"✅ Processing video...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Current time position in seconds\n",
    "    current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0\n",
    "\n",
    "    # ✅ Count detections up to current frame\n",
    "    while i < len(detections) and detections[i] <= current_time:\n",
    "        i += 1\n",
    "\n",
    "    # ✅ Add on-screen text\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Detections so far: {i}\",\n",
    "        (30, 50),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.2,\n",
    "        (255, 255, 255),\n",
    "        3\n",
    "    )\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"✅ Video created successfully!\")\n",
    "print(\"➡ Saved as:\", output_video)\n"
   ],
   "id": "2fef5462a4199eb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing video...\n",
      "✅ Video created successfully!\n",
      "➡ Saved as: linkedin_demo.mp4\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T14:35:55.198860Z",
     "start_time": "2025-11-14T12:08:38.551344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- Load your trained classifier ---\n",
    "model = load_model(\"traffic_sign_model.keras\")\n",
    "\n",
    "# --- Class names ---\n",
    "classes = {\n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)',\n",
    "    2:'Speed limit (50km/h)',\n",
    "    3:'Speed limit (60km/h)',\n",
    "    4:'Speed limit (70km/h)',\n",
    "    5:'Speed limit (80km/h)',\n",
    "    6:'End of speed limit (80km/h)',\n",
    "    7:'Speed limit (100km/h)',\n",
    "    8:'Speed limit (120km/h)',\n",
    "    9:'No passing',\n",
    "    10:'No passing veh over 3.5 tons',\n",
    "    11:'Right-of-way at intersection',\n",
    "    12:'Priority road',\n",
    "    13:'Yield',\n",
    "    14:'Stop',\n",
    "    15:'No vehicles',\n",
    "    16:'Veh > 3.5 tons prohibited',\n",
    "    17:'No entry',\n",
    "    18:'General caution',\n",
    "    19:'Dangerous curve left',\n",
    "    20:'Dangerous curve right',\n",
    "    21:'Double curve',\n",
    "    22:'Bumpy road',\n",
    "    23:'Slippery road',\n",
    "    24:'Road narrows on the right',\n",
    "    25:'Road work',\n",
    "    26:'Traffic signals',\n",
    "    27:'Pedestrians',\n",
    "    28:'Children crossing',\n",
    "    29:'Bicycles crossing',\n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing',\n",
    "    32:'End speed + passing limits',\n",
    "    33:'Turn right ahead',\n",
    "    34:'Turn left ahead',\n",
    "    35:'Ahead only',\n",
    "    36:'Go straight or right',\n",
    "    37:'Go straight or left',\n",
    "    38:'Keep right',\n",
    "    39:'Keep left',\n",
    "    40:'Roundabout mandatory',\n",
    "    41:'End of no passing',\n",
    "    42:'End no passing veh > 3.5 tons'\n",
    "}\n",
    "\n",
    "# --- Video setup ---\n",
    "cap = cv2.VideoCapture(\"clip_segment.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(\"traffic_sign_detection_demo.mp4\",\n",
    "                      cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "                      fps,\n",
    "                      (width, height))\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "print(\"✅ Processing video...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # --- Red color mask (traffic signs are often red-bordered) ---\n",
    "    lower1 = np.array([0, 70, 50])\n",
    "    upper1 = np.array([10, 255, 255])\n",
    "    lower2 = np.array([170, 70, 50])\n",
    "    upper2 = np.array([180, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower1, upper1) | cv2.inRange(hsv, lower2, upper2)\n",
    "\n",
    "    # --- Find contours (possible signs) ---\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # Filter out too-small or too-large areas\n",
    "        if w*h < 1000 or w*h > 50000:\n",
    "            continue\n",
    "\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "\n",
    "        # --- Classify the ROI ---\n",
    "        img = cv2.resize(roi, IMG_SIZE)\n",
    "        img = img.astype(\"float32\") / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        preds = model.predict(img, verbose=0)\n",
    "        class_id = np.argmax(preds)\n",
    "        conf = preds[0][class_id]\n",
    "\n",
    "        if conf > 0.80:\n",
    "            label = f\"{classes[class_id]} ({conf*100:.1f}%)\"\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ Done! Video saved as traffic_sign_detection_demo.mp4\")\n"
   ],
   "id": "750c0d7b1a073cad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing video...\n",
      "✅ Done! Video saved as traffic_sign_detection_demo.mp4\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
